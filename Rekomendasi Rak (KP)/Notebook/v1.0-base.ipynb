{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_barang = pd.read_csv('../Data/Raw/data_barang.csv', sep=';')\n",
    "data_rak = pd.read_csv('../Data/Raw/data_rak.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216 entries, 0 to 215\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   No                    209 non-null    float64\n",
      " 1   Kode Kelompok Barang  209 non-null    float64\n",
      " 2   Jenis Barang          210 non-null    object \n",
      " 3   Kuantitas             209 non-null    object \n",
      " 4   Satuan                209 non-null    object \n",
      " 5   No. Rak               209 non-null    object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 10.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_barang.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_barang.dropna(inplace=True)\n",
    "data_rak.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_no_rak(row):\n",
    "    # Split the No. Rak range\n",
    "    no_rak_range = row['No. Rak'].split(' - ')\n",
    "    start = int(no_rak_range[0])\n",
    "    end = int(no_rak_range[1])\n",
    "    \n",
    "    # Create a list of dictionaries, each representing a new row\n",
    "    rows = []\n",
    "    for rak in range(start, end + 1):\n",
    "        new_row = row.copy()\n",
    "        new_row['No. Rak'] = rak\n",
    "        rows.append(new_row)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "# Apply the function to expand the dataframe\n",
    "expanded_data = data_barang[data_barang['No. Rak'].str.contains('-')].apply(expand_no_rak, axis=1)\n",
    "\n",
    "# Flatten the list of lists into a new DataFrame\n",
    "expanded_data = pd.DataFrame([item for sublist in expanded_data for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_barang = data_barang[~data_barang['No. Rak'].str.contains('-')]\n",
    "data_barang = pd.concat([data_barang, expanded_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_rak[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo. Rak\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata_rak\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo. Rak\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dev/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dev/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dev/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dev/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dev/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[149], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_rak[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo. Rak\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_rak[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo. Rak\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "data_rak['No. Rak'] = data_rak['No. Rak'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_barang['No. Rak'] = data_barang['No. Rak'].astype(int)\n",
    "data_rak['No. Rak'] = data_rak['No. Rak'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3834 entries, 0 to 171\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   No                    3834 non-null   float64\n",
      " 1   Kode Kelompok Barang  3834 non-null   float64\n",
      " 2   Jenis Barang          3834 non-null   object \n",
      " 3   Kuantitas             3834 non-null   object \n",
      " 4   Satuan                3834 non-null   object \n",
      " 5   No. Rak               3834 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 209.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_barang.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama Rak</th>\n",
       "      <th>No. Rak</th>\n",
       "      <th>Posisi Rak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>A4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>K</td>\n",
       "      <td>428</td>\n",
       "      <td>K4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>K</td>\n",
       "      <td>429</td>\n",
       "      <td>K1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>K</td>\n",
       "      <td>430</td>\n",
       "      <td>K2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>K</td>\n",
       "      <td>431</td>\n",
       "      <td>K3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>K</td>\n",
       "      <td>432</td>\n",
       "      <td>K4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nama Rak  No. Rak Posisi Rak\n",
       "0          A        1         A1\n",
       "1          A        2         A2\n",
       "2          A        3         A3\n",
       "3          A        4         A4\n",
       "4          A        5         A1\n",
       "..       ...      ...        ...\n",
       "427        K      428         K4\n",
       "428        K      429         K1\n",
       "429        K      430         K2\n",
       "430        K      431         K3\n",
       "431        K      432         K4\n",
       "\n",
       "[432 rows x 3 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_barang.merge(data_rak, on='No. Rak', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('No', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Kuantitas'] = df['Kuantitas'].str.replace(',', '.')\n",
    "df['Kuantitas'] = pd.to_numeric(df['Kuantitas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "df['Jenis_Barang_econded'] = le.fit_transform(df['Jenis Barang'])\n",
    "df['Satuan_encoded'] = le.fit_transform(df['Satuan'])\n",
    "df['Nama_Rak_encoded'] = le.fit_transform(df['Nama Rak'])\n",
    "df['Posisi_Rak_encoded'] = le.fit_transform(df['Posisi Rak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and targets\n",
    "features = ['Kode Kelompok Barang', 'Jenis_Barang_econded', 'Kuantitas', 'Satuan_encoded']\n",
    "targets = ['Posisi_Rak_encoded', 'No. Rak']\n",
    "\n",
    "X = df[features]\n",
    "y = df[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier(random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultiOutputClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\">?<span>Documentation for MultiOutputClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier(random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(random_state=42))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN Model\n",
    "knn = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=3))\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Random Forest Model\n",
    "rf = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    for i, target in enumerate(targets):\n",
    "        print(f\"\\n{model_name} - {target} Accuracy:\", accuracy_score(y_test.iloc[:, i], y_pred[:, i]))\n",
    "        print(f\"{model_name} - {target} Classification Report:\")\n",
    "        print(classification_report(y_test.iloc[:, i], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN - Posisi_Rak_encoded Accuracy: 0.041278295605858856\n",
      "KNN - Posisi_Rak_encoded Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40         1\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.40      0.50      0.44         4\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.20      0.33      0.25         3\n",
      "           9       0.33      0.25      0.29         4\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.29      0.67      0.40         3\n",
      "          13       0.00      0.00      0.00         4\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00        10\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00        16\n",
      "          20       0.00      0.00      0.00        21\n",
      "          21       0.04      0.13      0.06        15\n",
      "          22       0.00      0.00      0.00        14\n",
      "          23       0.03      0.06      0.04        33\n",
      "          24       0.04      0.15      0.07        34\n",
      "          25       0.03      0.13      0.04        31\n",
      "          26       0.06      0.15      0.08        33\n",
      "          27       0.00      0.00      0.00        33\n",
      "          28       0.00      0.00      0.00        41\n",
      "          29       0.00      0.00      0.00        31\n",
      "          30       0.00      0.00      0.00        28\n",
      "          31       0.04      0.08      0.05        26\n",
      "          32       0.00      0.00      0.00        29\n",
      "          33       0.00      0.00      0.00        27\n",
      "          34       0.07      0.15      0.10        27\n",
      "          35       0.00      0.00      0.00        23\n",
      "          36       0.00      0.00      0.00        34\n",
      "          37       0.00      0.00      0.00        33\n",
      "          38       0.00      0.00      0.00        32\n",
      "          39       0.00      0.00      0.00        38\n",
      "          40       0.00      0.00      0.00        22\n",
      "          41       0.00      0.00      0.00        32\n",
      "          42       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.04       751\n",
      "   macro avg       0.04      0.08      0.05       751\n",
      "weighted avg       0.02      0.04      0.02       751\n",
      "\n",
      "\n",
      "KNN - No. Rak Accuracy: 0.0\n",
      "KNN - No. Rak Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00       1.0\n",
      "           3       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           6       0.00      0.00      0.00       0.0\n",
      "           8       0.00      0.00      0.00       0.0\n",
      "          12       0.00      0.00      0.00       1.0\n",
      "          14       0.00      0.00      0.00       1.0\n",
      "          15       0.00      0.00      0.00       1.0\n",
      "          16       0.00      0.00      0.00       0.0\n",
      "          20       0.00      0.00      0.00       0.0\n",
      "          22       0.00      0.00      0.00       1.0\n",
      "          24       0.00      0.00      0.00       1.0\n",
      "          25       0.00      0.00      0.00       1.0\n",
      "          27       0.00      0.00      0.00       2.0\n",
      "          35       0.00      0.00      0.00       2.0\n",
      "          42       0.00      0.00      0.00       1.0\n",
      "          43       0.00      0.00      0.00       1.0\n",
      "          45       0.00      0.00      0.00       0.0\n",
      "          48       0.00      0.00      0.00       1.0\n",
      "          50       0.00      0.00      0.00       0.0\n",
      "          51       0.00      0.00      0.00       1.0\n",
      "          54       0.00      0.00      0.00       1.0\n",
      "          58       0.00      0.00      0.00       0.0\n",
      "          63       0.00      0.00      0.00       0.0\n",
      "          66       0.00      0.00      0.00       1.0\n",
      "          70       0.00      0.00      0.00       0.0\n",
      "          71       0.00      0.00      0.00       1.0\n",
      "          72       0.00      0.00      0.00       0.0\n",
      "          75       0.00      0.00      0.00       1.0\n",
      "          76       0.00      0.00      0.00       0.0\n",
      "          86       0.00      0.00      0.00       1.0\n",
      "          87       0.00      0.00      0.00       0.0\n",
      "          89       0.00      0.00      0.00       0.0\n",
      "          90       0.00      0.00      0.00       0.0\n",
      "          91       0.00      0.00      0.00       1.0\n",
      "          93       0.00      0.00      0.00       0.0\n",
      "          94       0.00      0.00      0.00       0.0\n",
      "         100       0.00      0.00      0.00       1.0\n",
      "         105       0.00      0.00      0.00       0.0\n",
      "         106       0.00      0.00      0.00       1.0\n",
      "         107       0.00      0.00      0.00       1.0\n",
      "         110       0.00      0.00      0.00       0.0\n",
      "         113       0.00      0.00      0.00       0.0\n",
      "         114       0.00      0.00      0.00       0.0\n",
      "         119       0.00      0.00      0.00       1.0\n",
      "         123       0.00      0.00      0.00       1.0\n",
      "         126       0.00      0.00      0.00       0.0\n",
      "         130       0.00      0.00      0.00       0.0\n",
      "         133       0.00      0.00      0.00       1.0\n",
      "         134       0.00      0.00      0.00       0.0\n",
      "         138       0.00      0.00      0.00       1.0\n",
      "         141       0.00      0.00      0.00       0.0\n",
      "         143       0.00      0.00      0.00       1.0\n",
      "         148       0.00      0.00      0.00       1.0\n",
      "         150       0.00      0.00      0.00       1.0\n",
      "         153       0.00      0.00      0.00       0.0\n",
      "         154       0.00      0.00      0.00       1.0\n",
      "         155       0.00      0.00      0.00       1.0\n",
      "         158       0.00      0.00      0.00       5.0\n",
      "         159       0.00      0.00      0.00       2.0\n",
      "         160       0.00      0.00      0.00       1.0\n",
      "         161       0.00      0.00      0.00       1.0\n",
      "         162       0.00      0.00      0.00       4.0\n",
      "         164       0.00      0.00      0.00       2.0\n",
      "         165       0.00      0.00      0.00       2.0\n",
      "         166       0.00      0.00      0.00       1.0\n",
      "         167       0.00      0.00      0.00       6.0\n",
      "         168       0.00      0.00      0.00       3.0\n",
      "         170       0.00      0.00      0.00       3.0\n",
      "         171       0.00      0.00      0.00       3.0\n",
      "         173       0.00      0.00      0.00       5.0\n",
      "         174       0.00      0.00      0.00       3.0\n",
      "         175       0.00      0.00      0.00       3.0\n",
      "         176       0.00      0.00      0.00       3.0\n",
      "         177       0.00      0.00      0.00       5.0\n",
      "         178       0.00      0.00      0.00       5.0\n",
      "         179       0.00      0.00      0.00       1.0\n",
      "         180       0.00      0.00      0.00       5.0\n",
      "         181       0.00      0.00      0.00       3.0\n",
      "         182       0.00      0.00      0.00       3.0\n",
      "         183       0.00      0.00      0.00       5.0\n",
      "         184       0.00      0.00      0.00       3.0\n",
      "         185       0.00      0.00      0.00       2.0\n",
      "         186       0.00      0.00      0.00       4.0\n",
      "         187       0.00      0.00      0.00       1.0\n",
      "         188       0.00      0.00      0.00       4.0\n",
      "         189       0.00      0.00      0.00       3.0\n",
      "         190       0.00      0.00      0.00       2.0\n",
      "         191       0.00      0.00      0.00       1.0\n",
      "         192       0.00      0.00      0.00       4.0\n",
      "         193       0.00      0.00      0.00       3.0\n",
      "         194       0.00      0.00      0.00       3.0\n",
      "         195       0.00      0.00      0.00       2.0\n",
      "         196       0.00      0.00      0.00       2.0\n",
      "         197       0.00      0.00      0.00       5.0\n",
      "         198       0.00      0.00      0.00       3.0\n",
      "         199       0.00      0.00      0.00       4.0\n",
      "         200       0.00      0.00      0.00       4.0\n",
      "         201       0.00      0.00      0.00       2.0\n",
      "         202       0.00      0.00      0.00       1.0\n",
      "         203       0.00      0.00      0.00       2.0\n",
      "         204       0.00      0.00      0.00       3.0\n",
      "         205       0.00      0.00      0.00       3.0\n",
      "         206       0.00      0.00      0.00       2.0\n",
      "         207       0.00      0.00      0.00       1.0\n",
      "         208       0.00      0.00      0.00       0.0\n",
      "         209       0.00      0.00      0.00       3.0\n",
      "         210       0.00      0.00      0.00       5.0\n",
      "         211       0.00      0.00      0.00       4.0\n",
      "         212       0.00      0.00      0.00       1.0\n",
      "         213       0.00      0.00      0.00       2.0\n",
      "         214       0.00      0.00      0.00       4.0\n",
      "         215       0.00      0.00      0.00       4.0\n",
      "         216       0.00      0.00      0.00       4.0\n",
      "         217       0.00      0.00      0.00       3.0\n",
      "         218       0.00      0.00      0.00       2.0\n",
      "         219       0.00      0.00      0.00       1.0\n",
      "         220       0.00      0.00      0.00       3.0\n",
      "         221       0.00      0.00      0.00       3.0\n",
      "         222       0.00      0.00      0.00       2.0\n",
      "         223       0.00      0.00      0.00       1.0\n",
      "         224       0.00      0.00      0.00       3.0\n",
      "         225       0.00      0.00      0.00       1.0\n",
      "         226       0.00      0.00      0.00       3.0\n",
      "         227       0.00      0.00      0.00       5.0\n",
      "         228       0.00      0.00      0.00       2.0\n",
      "         229       0.00      0.00      0.00       2.0\n",
      "         230       0.00      0.00      0.00       4.0\n",
      "         231       0.00      0.00      0.00       4.0\n",
      "         232       0.00      0.00      0.00       3.0\n",
      "         233       0.00      0.00      0.00       1.0\n",
      "         234       0.00      0.00      0.00       2.0\n",
      "         235       0.00      0.00      0.00       1.0\n",
      "         236       0.00      0.00      0.00       1.0\n",
      "         237       0.00      0.00      0.00       3.0\n",
      "         238       0.00      0.00      0.00       4.0\n",
      "         239       0.00      0.00      0.00       3.0\n",
      "         240       0.00      0.00      0.00       2.0\n",
      "         241       0.00      0.00      0.00       3.0\n",
      "         242       0.00      0.00      0.00       3.0\n",
      "         243       0.00      0.00      0.00       2.0\n",
      "         244       0.00      0.00      0.00       3.0\n",
      "         245       0.00      0.00      0.00       3.0\n",
      "         246       0.00      0.00      0.00       4.0\n",
      "         247       0.00      0.00      0.00       3.0\n",
      "         248       0.00      0.00      0.00       1.0\n",
      "         249       0.00      0.00      0.00       2.0\n",
      "         250       0.00      0.00      0.00       6.0\n",
      "         251       0.00      0.00      0.00       3.0\n",
      "         252       0.00      0.00      0.00       5.0\n",
      "         253       0.00      0.00      0.00       3.0\n",
      "         254       0.00      0.00      0.00       5.0\n",
      "         255       0.00      0.00      0.00       3.0\n",
      "         256       0.00      0.00      0.00       3.0\n",
      "         257       0.00      0.00      0.00       2.0\n",
      "         258       0.00      0.00      0.00       1.0\n",
      "         259       0.00      0.00      0.00       3.0\n",
      "         260       0.00      0.00      0.00       1.0\n",
      "         261       0.00      0.00      0.00       4.0\n",
      "         262       0.00      0.00      0.00       2.0\n",
      "         263       0.00      0.00      0.00       3.0\n",
      "         264       0.00      0.00      0.00       1.0\n",
      "         265       0.00      0.00      0.00       3.0\n",
      "         266       0.00      0.00      0.00       3.0\n",
      "         267       0.00      0.00      0.00       2.0\n",
      "         268       0.00      0.00      0.00       1.0\n",
      "         269       0.00      0.00      0.00       5.0\n",
      "         270       0.00      0.00      0.00       2.0\n",
      "         271       0.00      0.00      0.00       3.0\n",
      "         272       0.00      0.00      0.00       2.0\n",
      "         273       0.00      0.00      0.00       2.0\n",
      "         274       0.00      0.00      0.00       3.0\n",
      "         275       0.00      0.00      0.00       3.0\n",
      "         276       0.00      0.00      0.00       3.0\n",
      "         278       0.00      0.00      0.00       1.0\n",
      "         279       0.00      0.00      0.00       2.0\n",
      "         280       0.00      0.00      0.00       2.0\n",
      "         281       0.00      0.00      0.00       3.0\n",
      "         282       0.00      0.00      0.00       7.0\n",
      "         283       0.00      0.00      0.00       1.0\n",
      "         284       0.00      0.00      0.00       4.0\n",
      "         285       0.00      0.00      0.00       3.0\n",
      "         286       0.00      0.00      0.00       4.0\n",
      "         287       0.00      0.00      0.00       3.0\n",
      "         288       0.00      0.00      0.00       2.0\n",
      "         289       0.00      0.00      0.00       1.0\n",
      "         290       0.00      0.00      0.00       2.0\n",
      "         291       0.00      0.00      0.00       2.0\n",
      "         292       0.00      0.00      0.00       2.0\n",
      "         293       0.00      0.00      0.00       5.0\n",
      "         294       0.00      0.00      0.00       1.0\n",
      "         295       0.00      0.00      0.00       4.0\n",
      "         296       0.00      0.00      0.00       3.0\n",
      "         297       0.00      0.00      0.00       4.0\n",
      "         298       0.00      0.00      0.00       1.0\n",
      "         299       0.00      0.00      0.00       2.0\n",
      "         300       0.00      0.00      0.00       4.0\n",
      "         301       0.00      0.00      0.00       2.0\n",
      "         302       0.00      0.00      0.00       3.0\n",
      "         303       0.00      0.00      0.00       1.0\n",
      "         305       0.00      0.00      0.00       2.0\n",
      "         306       0.00      0.00      0.00       2.0\n",
      "         307       0.00      0.00      0.00       2.0\n",
      "         309       0.00      0.00      0.00       3.0\n",
      "         310       0.00      0.00      0.00       4.0\n",
      "         311       0.00      0.00      0.00       3.0\n",
      "         312       0.00      0.00      0.00       3.0\n",
      "         313       0.00      0.00      0.00       1.0\n",
      "         314       0.00      0.00      0.00       4.0\n",
      "         315       0.00      0.00      0.00       3.0\n",
      "         316       0.00      0.00      0.00       2.0\n",
      "         317       0.00      0.00      0.00       3.0\n",
      "         318       0.00      0.00      0.00       3.0\n",
      "         319       0.00      0.00      0.00       3.0\n",
      "         320       0.00      0.00      0.00       1.0\n",
      "         321       0.00      0.00      0.00       1.0\n",
      "         322       0.00      0.00      0.00       3.0\n",
      "         323       0.00      0.00      0.00       4.0\n",
      "         324       0.00      0.00      0.00       2.0\n",
      "         325       0.00      0.00      0.00       2.0\n",
      "         326       0.00      0.00      0.00       1.0\n",
      "         328       0.00      0.00      0.00       4.0\n",
      "         329       0.00      0.00      0.00       2.0\n",
      "         330       0.00      0.00      0.00       2.0\n",
      "         331       0.00      0.00      0.00       1.0\n",
      "         332       0.00      0.00      0.00       3.0\n",
      "         334       0.00      0.00      0.00       3.0\n",
      "         335       0.00      0.00      0.00       2.0\n",
      "         336       0.00      0.00      0.00       3.0\n",
      "         338       0.00      0.00      0.00       1.0\n",
      "         339       0.00      0.00      0.00       2.0\n",
      "         340       0.00      0.00      0.00       4.0\n",
      "         341       0.00      0.00      0.00       2.0\n",
      "         342       0.00      0.00      0.00       2.0\n",
      "         343       0.00      0.00      0.00       2.0\n",
      "         344       0.00      0.00      0.00       1.0\n",
      "         345       0.00      0.00      0.00       2.0\n",
      "         346       0.00      0.00      0.00       2.0\n",
      "         347       0.00      0.00      0.00       4.0\n",
      "         348       0.00      0.00      0.00       2.0\n",
      "         349       0.00      0.00      0.00       5.0\n",
      "         350       0.00      0.00      0.00       3.0\n",
      "         351       0.00      0.00      0.00       4.0\n",
      "         352       0.00      0.00      0.00       1.0\n",
      "         354       0.00      0.00      0.00       3.0\n",
      "         355       0.00      0.00      0.00       3.0\n",
      "         356       0.00      0.00      0.00       4.0\n",
      "         357       0.00      0.00      0.00       2.0\n",
      "         358       0.00      0.00      0.00       4.0\n",
      "         360       0.00      0.00      0.00       2.0\n",
      "         361       0.00      0.00      0.00       1.0\n",
      "         362       0.00      0.00      0.00       5.0\n",
      "         363       0.00      0.00      0.00       4.0\n",
      "         364       0.00      0.00      0.00       5.0\n",
      "         365       0.00      0.00      0.00       1.0\n",
      "         366       0.00      0.00      0.00       1.0\n",
      "         367       0.00      0.00      0.00       4.0\n",
      "         368       0.00      0.00      0.00       3.0\n",
      "         369       0.00      0.00      0.00       4.0\n",
      "         370       0.00      0.00      0.00       6.0\n",
      "         371       0.00      0.00      0.00       3.0\n",
      "         372       0.00      0.00      0.00       3.0\n",
      "         373       0.00      0.00      0.00       1.0\n",
      "         374       0.00      0.00      0.00       3.0\n",
      "         375       0.00      0.00      0.00       3.0\n",
      "         376       0.00      0.00      0.00       2.0\n",
      "         377       0.00      0.00      0.00       2.0\n",
      "         378       0.00      0.00      0.00       3.0\n",
      "         379       0.00      0.00      0.00       4.0\n",
      "         380       0.00      0.00      0.00       4.0\n",
      "         381       0.00      0.00      0.00       3.0\n",
      "         382       0.00      0.00      0.00       1.0\n",
      "         384       0.00      0.00      0.00       1.0\n",
      "         385       0.00      0.00      0.00       2.0\n",
      "         387       0.00      0.00      0.00       3.0\n",
      "         388       0.00      0.00      0.00       4.0\n",
      "         389       0.00      0.00      0.00       1.0\n",
      "         391       0.00      0.00      0.00       1.0\n",
      "         392       0.00      0.00      0.00       2.0\n",
      "         393       0.00      0.00      0.00       3.0\n",
      "         394       0.00      0.00      0.00       2.0\n",
      "         395       0.00      0.00      0.00       2.0\n",
      "         396       0.00      0.00      0.00       4.0\n",
      "         397       0.00      0.00      0.00       5.0\n",
      "         398       0.00      0.00      0.00       2.0\n",
      "         399       0.00      0.00      0.00       4.0\n",
      "         400       0.00      0.00      0.00       5.0\n",
      "         401       0.00      0.00      0.00       2.0\n",
      "         402       0.00      0.00      0.00       2.0\n",
      "         403       0.00      0.00      0.00       1.0\n",
      "         404       0.00      0.00      0.00       2.0\n",
      "         405       0.00      0.00      0.00       3.0\n",
      "         406       0.00      0.00      0.00       3.0\n",
      "         407       0.00      0.00      0.00       2.0\n",
      "         408       0.00      0.00      0.00       2.0\n",
      "         409       0.00      0.00      0.00       2.0\n",
      "         410       0.00      0.00      0.00       1.0\n",
      "         411       0.00      0.00      0.00       5.0\n",
      "         412       0.00      0.00      0.00       2.0\n",
      "         413       0.00      0.00      0.00       6.0\n",
      "         414       0.00      0.00      0.00       5.0\n",
      "         415       0.00      0.00      0.00       4.0\n",
      "         416       0.00      0.00      0.00       4.0\n",
      "         417       0.00      0.00      0.00       3.0\n",
      "         418       0.00      0.00      0.00       2.0\n",
      "         419       0.00      0.00      0.00       2.0\n",
      "         420       0.00      0.00      0.00       2.0\n",
      "         421       0.00      0.00      0.00       3.0\n",
      "         422       0.00      0.00      0.00       1.0\n",
      "         423       0.00      0.00      0.00       2.0\n",
      "         424       0.00      0.00      0.00       6.0\n",
      "         425       0.00      0.00      0.00       4.0\n",
      "         426       0.00      0.00      0.00       1.0\n",
      "         427       0.00      0.00      0.00       4.0\n",
      "         428       0.00      0.00      0.00       2.0\n",
      "         429       0.00      0.00      0.00       4.0\n",
      "         430       0.00      0.00      0.00       3.0\n",
      "         431       0.00      0.00      0.00       2.0\n",
      "         432       0.00      0.00      0.00       3.0\n",
      "\n",
      "    accuracy                           0.00     751.0\n",
      "   macro avg       0.00      0.00      0.00     751.0\n",
      "weighted avg       0.00      0.00      0.00     751.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate KNN\n",
    "evaluate_model(knn, X_test_scaled, y_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - Posisi_Rak_encoded Accuracy: 0.011984021304926764\n",
      "Random Forest - Posisi_Rak_encoded Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.50      0.14      0.22         7\n",
      "           6       0.17      0.50      0.25         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.50      0.25      0.33         4\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.50      1.00      0.67         1\n",
      "          12       0.33      0.33      0.33         3\n",
      "          13       0.00      0.00      0.00         4\n",
      "          14       0.33      1.00      0.50         1\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00        10\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00        16\n",
      "          20       0.00      0.00      0.00        21\n",
      "          21       0.00      0.00      0.00        15\n",
      "          22       0.00      0.00      0.00        14\n",
      "          23       0.00      0.00      0.00        33\n",
      "          24       0.00      0.00      0.00        34\n",
      "          25       0.00      0.00      0.00        31\n",
      "          26       0.00      0.00      0.00        33\n",
      "          27       0.00      0.00      0.00        33\n",
      "          28       0.00      0.00      0.00        41\n",
      "          29       0.00      0.00      0.00        31\n",
      "          30       0.00      0.00      0.00        28\n",
      "          31       0.01      0.04      0.02        26\n",
      "          32       0.00      0.00      0.00        29\n",
      "          33       0.00      0.00      0.00        27\n",
      "          34       0.00      0.00      0.00        27\n",
      "          35       0.00      0.00      0.00        23\n",
      "          36       0.00      0.00      0.00        34\n",
      "          37       0.00      0.00      0.00        33\n",
      "          38       0.50      0.03      0.06        32\n",
      "          39       0.00      0.00      0.00        38\n",
      "          40       0.01      0.05      0.02        22\n",
      "          41       0.00      0.00      0.00        32\n",
      "          42       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.01       751\n",
      "   macro avg       0.07      0.08      0.06       751\n",
      "weighted avg       0.03      0.01      0.01       751\n",
      "\n",
      "\n",
      "Random Forest - No. Rak Accuracy: 0.0013315579227696406\n",
      "Random Forest - No. Rak Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         1\n",
      "          94       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         1\n",
      "         148       0.33      1.00      0.50         1\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         5\n",
      "         159       0.00      0.00      0.00         2\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         4\n",
      "         164       0.00      0.00      0.00         2\n",
      "         165       0.00      0.00      0.00         2\n",
      "         166       0.00      0.00      0.00         1\n",
      "         167       0.00      0.00      0.00         6\n",
      "         168       0.00      0.00      0.00         3\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         3\n",
      "         173       0.00      0.00      0.00         5\n",
      "         174       0.00      0.00      0.00         3\n",
      "         175       0.00      0.00      0.00         3\n",
      "         176       0.00      0.00      0.00         3\n",
      "         177       0.00      0.00      0.00         5\n",
      "         178       0.00      0.00      0.00         5\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         5\n",
      "         181       0.00      0.00      0.00         3\n",
      "         182       0.00      0.00      0.00         3\n",
      "         183       0.00      0.00      0.00         5\n",
      "         184       0.00      0.00      0.00         3\n",
      "         185       0.00      0.00      0.00         2\n",
      "         186       0.00      0.00      0.00         4\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         4\n",
      "         189       0.00      0.00      0.00         3\n",
      "         190       0.00      0.00      0.00         2\n",
      "         191       0.00      0.00      0.00         1\n",
      "         192       0.00      0.00      0.00         4\n",
      "         193       0.00      0.00      0.00         3\n",
      "         194       0.00      0.00      0.00         3\n",
      "         195       0.00      0.00      0.00         2\n",
      "         196       0.00      0.00      0.00         2\n",
      "         197       0.00      0.00      0.00         5\n",
      "         198       0.00      0.00      0.00         3\n",
      "         199       0.00      0.00      0.00         4\n",
      "         200       0.00      0.00      0.00         4\n",
      "         201       0.00      0.00      0.00         2\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         2\n",
      "         204       0.00      0.00      0.00         3\n",
      "         205       0.00      0.00      0.00         3\n",
      "         206       0.00      0.00      0.00         2\n",
      "         207       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         3\n",
      "         210       0.00      0.00      0.00         5\n",
      "         211       0.00      0.00      0.00         4\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       0.00      0.00      0.00         2\n",
      "         214       0.00      0.00      0.00         4\n",
      "         215       0.00      0.00      0.00         4\n",
      "         216       0.00      0.00      0.00         4\n",
      "         217       0.00      0.00      0.00         3\n",
      "         218       0.00      0.00      0.00         2\n",
      "         219       0.00      0.00      0.00         1\n",
      "         220       0.00      0.00      0.00         3\n",
      "         221       0.00      0.00      0.00         3\n",
      "         222       0.00      0.00      0.00         2\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         3\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         3\n",
      "         227       0.00      0.00      0.00         5\n",
      "         228       0.00      0.00      0.00         2\n",
      "         229       0.00      0.00      0.00         2\n",
      "         230       0.00      0.00      0.00         4\n",
      "         231       0.00      0.00      0.00         4\n",
      "         232       0.00      0.00      0.00         3\n",
      "         233       0.00      0.00      0.00         1\n",
      "         234       0.00      0.00      0.00         2\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         3\n",
      "         238       0.00      0.00      0.00         4\n",
      "         239       0.00      0.00      0.00         3\n",
      "         240       0.00      0.00      0.00         2\n",
      "         241       0.00      0.00      0.00         3\n",
      "         242       0.00      0.00      0.00         3\n",
      "         243       0.00      0.00      0.00         2\n",
      "         244       0.00      0.00      0.00         3\n",
      "         245       0.00      0.00      0.00         3\n",
      "         246       0.00      0.00      0.00         4\n",
      "         247       0.00      0.00      0.00         3\n",
      "         248       0.00      0.00      0.00         1\n",
      "         249       0.00      0.00      0.00         2\n",
      "         250       0.00      0.00      0.00         6\n",
      "         251       0.00      0.00      0.00         3\n",
      "         252       0.00      0.00      0.00         5\n",
      "         253       0.00      0.00      0.00         3\n",
      "         254       0.00      0.00      0.00         5\n",
      "         255       0.00      0.00      0.00         3\n",
      "         256       0.00      0.00      0.00         3\n",
      "         257       0.00      0.00      0.00         2\n",
      "         258       0.00      0.00      0.00         1\n",
      "         259       0.00      0.00      0.00         3\n",
      "         260       0.00      0.00      0.00         1\n",
      "         261       0.00      0.00      0.00         4\n",
      "         262       0.00      0.00      0.00         2\n",
      "         263       0.00      0.00      0.00         3\n",
      "         264       0.00      0.00      0.00         1\n",
      "         265       0.00      0.00      0.00         3\n",
      "         266       0.00      0.00      0.00         3\n",
      "         267       0.00      0.00      0.00         2\n",
      "         268       0.00      0.00      0.00         1\n",
      "         269       0.00      0.00      0.00         5\n",
      "         270       0.00      0.00      0.00         2\n",
      "         271       0.00      0.00      0.00         3\n",
      "         272       0.00      0.00      0.00         2\n",
      "         273       0.00      0.00      0.00         2\n",
      "         274       0.00      0.00      0.00         3\n",
      "         275       0.00      0.00      0.00         3\n",
      "         276       0.00      0.00      0.00         3\n",
      "         278       0.00      0.00      0.00         1\n",
      "         279       0.00      0.00      0.00         2\n",
      "         280       0.00      0.00      0.00         2\n",
      "         281       0.00      0.00      0.00         3\n",
      "         282       0.00      0.00      0.00         7\n",
      "         283       0.00      0.00      0.00         1\n",
      "         284       0.00      0.00      0.00         4\n",
      "         285       0.00      0.00      0.00         3\n",
      "         286       0.00      0.00      0.00         4\n",
      "         287       0.00      0.00      0.00         3\n",
      "         288       0.00      0.00      0.00         2\n",
      "         289       0.00      0.00      0.00         1\n",
      "         290       0.00      0.00      0.00         2\n",
      "         291       0.00      0.00      0.00         2\n",
      "         292       0.00      0.00      0.00         2\n",
      "         293       0.00      0.00      0.00         5\n",
      "         294       0.00      0.00      0.00         1\n",
      "         295       0.00      0.00      0.00         4\n",
      "         296       0.00      0.00      0.00         3\n",
      "         297       0.00      0.00      0.00         4\n",
      "         298       0.00      0.00      0.00         1\n",
      "         299       0.00      0.00      0.00         2\n",
      "         300       0.00      0.00      0.00         4\n",
      "         301       0.00      0.00      0.00         2\n",
      "         302       0.00      0.00      0.00         3\n",
      "         303       0.00      0.00      0.00         1\n",
      "         305       0.00      0.00      0.00         2\n",
      "         306       0.00      0.00      0.00         2\n",
      "         307       0.00      0.00      0.00         2\n",
      "         309       0.00      0.00      0.00         3\n",
      "         310       0.00      0.00      0.00         4\n",
      "         311       0.00      0.00      0.00         3\n",
      "         312       0.00      0.00      0.00         3\n",
      "         313       0.00      0.00      0.00         1\n",
      "         314       0.00      0.00      0.00         4\n",
      "         315       0.00      0.00      0.00         3\n",
      "         316       0.00      0.00      0.00         2\n",
      "         317       0.00      0.00      0.00         3\n",
      "         318       0.00      0.00      0.00         3\n",
      "         319       0.00      0.00      0.00         3\n",
      "         320       0.00      0.00      0.00         1\n",
      "         321       0.00      0.00      0.00         1\n",
      "         322       0.00      0.00      0.00         3\n",
      "         323       0.00      0.00      0.00         4\n",
      "         324       0.00      0.00      0.00         2\n",
      "         325       0.00      0.00      0.00         2\n",
      "         326       0.00      0.00      0.00         1\n",
      "         328       0.00      0.00      0.00         4\n",
      "         329       0.00      0.00      0.00         2\n",
      "         330       0.00      0.00      0.00         2\n",
      "         331       0.00      0.00      0.00         1\n",
      "         332       0.00      0.00      0.00         3\n",
      "         334       0.00      0.00      0.00         3\n",
      "         335       0.00      0.00      0.00         2\n",
      "         336       0.00      0.00      0.00         3\n",
      "         338       0.00      0.00      0.00         1\n",
      "         339       0.00      0.00      0.00         2\n",
      "         340       0.00      0.00      0.00         4\n",
      "         341       0.00      0.00      0.00         2\n",
      "         342       0.00      0.00      0.00         2\n",
      "         343       0.00      0.00      0.00         2\n",
      "         344       0.00      0.00      0.00         1\n",
      "         345       0.00      0.00      0.00         2\n",
      "         346       0.00      0.00      0.00         2\n",
      "         347       0.00      0.00      0.00         4\n",
      "         348       0.00      0.00      0.00         2\n",
      "         349       0.00      0.00      0.00         5\n",
      "         350       0.00      0.00      0.00         3\n",
      "         351       0.00      0.00      0.00         4\n",
      "         352       0.00      0.00      0.00         1\n",
      "         354       0.00      0.00      0.00         3\n",
      "         355       0.00      0.00      0.00         3\n",
      "         356       0.00      0.00      0.00         4\n",
      "         357       0.00      0.00      0.00         2\n",
      "         358       0.00      0.00      0.00         4\n",
      "         359       0.00      0.00      0.00         0\n",
      "         360       0.00      0.00      0.00         2\n",
      "         361       0.00      0.00      0.00         1\n",
      "         362       0.00      0.00      0.00         5\n",
      "         363       0.00      0.00      0.00         4\n",
      "         364       0.00      0.00      0.00         5\n",
      "         365       0.00      0.00      0.00         1\n",
      "         366       0.00      0.00      0.00         1\n",
      "         367       0.00      0.00      0.00         4\n",
      "         368       0.00      0.00      0.00         3\n",
      "         369       0.00      0.00      0.00         4\n",
      "         370       0.00      0.00      0.00         6\n",
      "         371       0.00      0.00      0.00         3\n",
      "         372       0.00      0.00      0.00         3\n",
      "         373       0.00      0.00      0.00         1\n",
      "         374       0.00      0.00      0.00         3\n",
      "         375       0.00      0.00      0.00         3\n",
      "         376       0.00      0.00      0.00         2\n",
      "         377       0.00      0.00      0.00         2\n",
      "         378       0.00      0.00      0.00         3\n",
      "         379       0.00      0.00      0.00         4\n",
      "         380       0.00      0.00      0.00         4\n",
      "         381       0.00      0.00      0.00         3\n",
      "         382       0.00      0.00      0.00         1\n",
      "         384       0.00      0.00      0.00         1\n",
      "         385       0.00      0.00      0.00         2\n",
      "         387       0.00      0.00      0.00         3\n",
      "         388       0.00      0.00      0.00         4\n",
      "         389       0.00      0.00      0.00         1\n",
      "         391       0.00      0.00      0.00         1\n",
      "         392       0.00      0.00      0.00         2\n",
      "         393       0.00      0.00      0.00         3\n",
      "         394       0.00      0.00      0.00         2\n",
      "         395       0.00      0.00      0.00         2\n",
      "         396       0.00      0.00      0.00         4\n",
      "         397       0.00      0.00      0.00         5\n",
      "         398       0.00      0.00      0.00         2\n",
      "         399       0.00      0.00      0.00         4\n",
      "         400       0.00      0.00      0.00         5\n",
      "         401       0.00      0.00      0.00         2\n",
      "         402       0.00      0.00      0.00         2\n",
      "         403       0.00      0.00      0.00         1\n",
      "         404       0.00      0.00      0.00         2\n",
      "         405       0.00      0.00      0.00         3\n",
      "         406       0.00      0.00      0.00         3\n",
      "         407       0.00      0.00      0.00         2\n",
      "         408       0.00      0.00      0.00         2\n",
      "         409       0.00      0.00      0.00         2\n",
      "         410       0.00      0.00      0.00         1\n",
      "         411       0.00      0.00      0.00         5\n",
      "         412       0.00      0.00      0.00         2\n",
      "         413       0.00      0.00      0.00         6\n",
      "         414       0.00      0.00      0.00         5\n",
      "         415       0.00      0.00      0.00         4\n",
      "         416       0.00      0.00      0.00         4\n",
      "         417       0.00      0.00      0.00         3\n",
      "         418       0.00      0.00      0.00         2\n",
      "         419       0.00      0.00      0.00         2\n",
      "         420       0.00      0.00      0.00         2\n",
      "         421       0.00      0.00      0.00         3\n",
      "         422       0.00      0.00      0.00         1\n",
      "         423       0.00      0.00      0.00         2\n",
      "         424       0.00      0.00      0.00         6\n",
      "         425       0.00      0.00      0.00         4\n",
      "         426       0.00      0.00      0.00         1\n",
      "         427       0.00      0.00      0.00         4\n",
      "         428       0.00      0.00      0.00         2\n",
      "         429       0.00      0.00      0.00         4\n",
      "         430       0.00      0.00      0.00         3\n",
      "         431       0.00      0.00      0.00         2\n",
      "         432       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.00       751\n",
      "   macro avg       0.00      0.00      0.00       751\n",
      "weighted avg       0.00      0.00      0.00       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest\n",
    "evaluate_model(rf, X_test_scaled, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_rack(model, scaler, product_info):\n",
    "    # Prepare the input\n",
    "    input_data = np.array([[\n",
    "        product_info['Kode Kelompok Barang'],\n",
    "        product_info['Jenis Barang'],\n",
    "        product_info['Kuantitas'],\n",
    "        product_info['Satuan_encoded']\n",
    "    ]])\n",
    "    \n",
    "    # Scale the input\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(input_scaled)[0]\n",
    "    \n",
    "    return predictions[0], predictions[1]  # Posisi_Rak_encoded, No. Rak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "new_product = {\n",
    "    'Kode Kelompok Barang': 1000,\n",
    "    'Jenis Barang': 100203.0,\n",
    "    'Kuantitas': 5000,\n",
    "    'Satuan_encoded': 3  # Assuming 'pcs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_posisi, knn_no = recommend_rack(knn, scaler, new_product)\n",
    "rf_posisi, rf_no = recommend_rack(rf, scaler, new_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendation for new product:\n",
      "KNN Recommendation - Posisi Rak encoded: 6 No. Rak: 56\n",
      "Random Forest Recommendation - Posisi Rak encoded: 10 No. Rak: 68\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRecommendation for new product:\")\n",
    "print(\"KNN Recommendation - Posisi Rak encoded:\", knn_posisi, \"No. Rak:\", knn_no)\n",
    "print(\"Random Forest Recommendation - Posisi Rak encoded:\", rf_posisi, \"No. Rak:\", rf_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Kode Kelompok Barang, Importance: 0.1434748234176526\n",
      "Feature: Jenis_Barang_econded, Importance: 0.09113886366561741\n",
      "Feature: Kuantitas, Importance: 0.7125932367673089\n",
      "Feature: Satuan_encoded, Importance: 0.052793076149421095\n"
     ]
    }
   ],
   "source": [
    "feature_importance = rf.estimators_[0].feature_importances_\n",
    "for feature, importance in zip(features, feature_importance):\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
